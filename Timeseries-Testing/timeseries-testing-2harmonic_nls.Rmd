---
title: "timeseries-testing"
output: html_document
---

## Read in timeseries and clean

```{r}

library(imputeTS)
library(dplyr)
library(signal) # Savitsky-Golay fitting
library(dplyr)
library(zoo)
library(ggplot2)

# need to read in, because regardless of whether use smooth or unsmoothed EVI for the other fitting methods, must start with nonsmoothed EVI here. doubly smoothed EVI (20, 20) is in the csv
ts <- read.csv('point1.csv')[,1:2]

colnames(ts) <- c('date', 'EVI_raw')
ts$date <- as.Date(ts$date, '%d-%h-%y')
ts$day <- as.numeric(ts$date - as.Date('2016-08-01')) # number of days

year <- 2017
year_start = year - 1
year_end = year

# plot raw EVI for looking at datq quality, DOY for rising and falling limbs
plot(ts[ts$day >= 0 & ts$day <= 365,]$day, ts[ts$day >= 0 & ts$day <= 365,]$EVI_raw, main = 'raw EVI', xlab = 'DOY after Aug 1', ylab = 'EVI')

```

## Helper functions

```{r}

# function to smooth by certain number of days (not by index). numDays creates +/- window; so actual smoothing window is - numDays to + numDays
smooth_by_days <- function(numDays, t, values) {
  
  smoothed <- numeric(length(values))
  
  for (index in 1:length(values)) {
    
    # get time window
    day_center <- t[index]
    day_start <- day_center - numDays
    day_end <- day_center + numDays
    
    # get indices corresponding to time window
    indices <- which(t >= day_start & t <= day_end)
    
    # get average of values over the indices and save
    mean_value <- mean(values[indices], na.rm = TRUE)
    
    smoothed[index] <- mean_value
    
  }
  
  return(smoothed)
}

# calculate first derivative of smoothed EVI (forward 1st order difference)
calc_1st_deriv <- function(values) {
  
  derivatives <- numeric(length(values))
  
  for (index in 1:(length(values)-1)) {

    derivative <- values[index + 1] - values[index]

    derivatives[index] <- derivative
  }
  
  derivatives[length(values)] <- derivatives[length(values) - 1] # to make sure the 1st derivative length still matches total time
  
  return(derivatives)
}

```

## Harmonic fitting with estimated omega

```{r}

# harmonic fitting function (estimates omega)
# given: fitting degree (window size for smoothing EVI; timeseries as df, columns of date and raw EVI; number of points to take out randomly; the DOY from Aug 1 of the windows over which can find the rising and falling limbs of the first crop
# returns: quarter period and peak date
# the fittingStartDay and fittingEndDay are the windows over which to fit harmonic function; make sure they cover the peak(s) but not the dry season

#risingLimb_start_DOY <- 50
#risingLimb_end_DOY <- 120
#fallingLimb_start_DOY <- 120
#fallingLimb_end_DOY <- 190 
#window_EVI_1 <- 0
#window_EVI_2 <- 0
#numMissingPts <- 8
#fittingStartDay <- '2016-10-01'
#fittingEndDay <- '2017-07-01'

harmonic_nls_algorithm <- function(ts, window_EVI_1, window_EVI_2, numMissingPts, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {
  
  # cut EVI to only Aug 1, 2016 to April 1, 2017, then take out random points
  targeted_start_day <- as.numeric(as.Date('2016-08-01') - as.Date('2016-08-01'))
  targeted_end_day <- as.numeric(as.Date('2017-04-01') - as.Date('2016-08-01'))
  targeted_days <- which(ts$day >= targeted_start_day & ts$day <= targeted_end_day) # index of days to target
  ts <- ts[targeted_days,]
  
  # cut out randomly selected missing dates; first make sure the points are sampled from days that have data
  missing_days <- sample(unique(ts[complete.cases(ts),]$day), numMissingPts, replace = F) # days to take out
  ts$EVI_raw[ts$day %in% missing_days] <- NA # replace the randomly selected dates' EVI_raw with 'NA'

  # cut EVI to only fittingStartDay and fittingEndDay
  fitting_start_day <- as.numeric(as.Date(fittingStartDay) - as.Date('2016-08-01'))
  fitting_end_day <- as.numeric(as.Date(fittingEndDay) - as.Date('2016-08-01'))
  fitting_days <- which(ts$day >= fitting_start_day & ts$day <= fitting_end_day) # index of days to fitting
  ts <- ts[fitting_days,]
  
  EVI_raw <- ts$EVI_raw
  t <- ts$day
  
  # smooth EVI series by 20 days, then 20 days
  EVI_smoothed1 <- smooth_by_days(window_EVI_1, t, EVI_raw)
  EVI_smoothed2 <- smooth_by_days(window_EVI_2, t, EVI_smoothed1)
  
  # clean up EVI_smoothed2. for every date, replace with mean of the 2 EVI points and linearly interpolate at NaN times
  ts_R <- data.frame(t, EVI_smoothed2)
  ts_R <- ts_R %>% group_by(t) %>%
          summarise_at(vars(EVI_smoothed2), mean)

  # from here, the data won't be doubled on each date!
  EVI_smoothed2 <- na.approx(ts_R$EVI_smoothed2, na.rm = FALSE)
  # there may still be NA's at tails of EVI_smoothed2. replace these with the nearest non-NA or the average if have multiple NA's
  NA_location <- which(is.na(EVI_smoothed2))
  if (length(NA_location) == 1) { # if there is an NA in EVI_smoothed2, replace it with nearest value
    if (NA_location == 1) {EVI_smoothed2[1] <- EVI_smoothed2[2]}
    else if ( NA_location == length(EVI_smoothed2)) {EVI_smoothed2[length(EVI_smoothed2)] <- EVI_smoothed2[length(EVI_smoothed2) - 1]}
  }
  
  if (length(NA_location) > 1) {
    EVI_smoothed2[which(is.na(EVI_smoothed2))] <- mean(EVI_smoothed2, na.rm = TRUE)
    }

  ts_R$EVI_smoothed2 <- EVI_smoothed2
  
  # harmonic fitting
  t_fitting <- ts_R$t/(2*3.14)
  
  #plot(t_fitting, EVI_smoothed2)
  #lines(t_fitting, EVI_smoothed2, col = "green")
    
  # Model that estimates w. if smoothing fails, use try to return NA's for midSeason and quarterPeriod_comparable and exit function
  model_nls1 <- try(nls(EVI_smoothed2~c1 + c2*t_fitting + c3*(t_fitting^2) + c4*sin(w*t_fitting) + c5*cos(w*t_fitting) +
               c6*sin(2*w*t_fitting) + c7*cos(2*w*t_fitting), 
             start = list(c1 = -1, c2 = 0.1, c3 = 0.1, 
                          c4 = 0.1, c5 = 0.1, c6 = 0,
                          c7 = 0, w = 0.3
                          ),
             control = nls.control(maxiter = 2000, minFactor = 1e-7))
  )
  if(is(model_nls1, "try-error")) {
    results <- c(NA, NA)
    names(results) <- c('midSeason', 'quarterPd_comparable')
  
  return(results)
  }

  #lines(t_fitting, fitted(model_nls1), col = "red")
  
  # retreive omega from estimated coefficients
  omega <- summary(model_nls1)$parameters[8]
  quarter_period <- 3.14/(2*omega)
  period <- 2*3.14/omega
  
  # find phenological dates, first make sure the dates found are for first crop, first or second half
  firstHalf_dates <- which(ts_R$t >= risingLimb_start_DOY & ts_R$t <= risingLimb_end_DOY) # rising limb of first crop
  t_firstHalf <- ts_R$t[firstHalf_dates]
  fittedEVI_firstHalf <- fitted(model_nls1)[firstHalf_dates]
  
  secondHalf_dates <- which(ts_R$t >= fallingLimb_start_DOY & ts_R$t <= fallingLimb_end_DOY) # falling limb of first crop
  t_secondHalf <- ts_R$t[secondHalf_dates]
  fittedEVI_secondHalf <- fitted(model_nls1)[secondHalf_dates]
  
  firstCrop_dates <- which(ts_R$t >= risingLimb_start_DOY & ts_R$t <= fallingLimb_end_DOY) # first crop
  t_firstCrop <- ts_R$t[firstCrop_dates]
  fittedEVI_firstCrop <- fitted(model_nls1)[firstCrop_dates]
  
  # date and value of max EVI
  maxEVI <- max(fittedEVI_firstCrop, na.rm = TRUE)
  minEVI_left <- min(fittedEVI_firstHalf, na.rm = TRUE)
  minEVI_right <- min(fittedEVI_secondHalf, na.rm = TRUE)
  
  date_min = approx(x = fittedEVI_firstCrop, y = t_firstCrop, xout = minEVI_left)$y
  
  # find phenological dates
  rightOfPeakEVI <- 0.9*(maxEVI - minEVI_left) + minEVI_left
  leftOfPeakEVI <- 0.9*(maxEVI - minEVI_right) + minEVI_right

  date_rightOfPeak <- approx(x = fittedEVI_secondHalf, y = t_secondHalf, xout = rightOfPeakEVI)$y
  date_leftOfPeak <- approx(x = fittedEVI_firstHalf, y = t_firstHalf, xout = leftOfPeakEVI)$y
  
  if (is.na(date_rightOfPeak)) {date_rightOfPeak <- mean(risingLimb_start_DOY, fallingLimb_end_DOY)}
  if (is.na(date_leftOfPeak)) {date_leftOfPeak <- mean(risingLimb_start_DOY, fallingLimb_end_DOY)}

  midSeason <- mean(c(date_rightOfPeak, date_leftOfPeak))
  quarter_period_comparable <- (midSeason - date_min)/2
  
  results <- c(midSeason, quarter_period_comparable)
  names(results) <- c('midSeason', 'quarterPd_comparable')
  
  return(results)
}


#print(harmonic_nls_algorithm(ts, 10, 20, 0, 40, 140, 130, 240, '2016-10-01', '2017-07-01'))

# takes elimPoints, the vector of number of points to eliminate, and numRuns, the number of runs to do per number of points eliminated
run_harmonic_nls_algorithm <- function(ts, numRuns, elimPoints, window_EVI_1, window_EVI_2, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {

  # to hold results
  peak_results <- matrix(nrow = numRuns, ncol = length(elimPoints))
  quarterPd_results <- matrix(nrow = numRuns, ncol = length(elimPoints))
  
  # run with appropriate number of missing points
  for (numMissingPts_index in 1:length(elimPoints)) {
    for (runIndex in 1:numRuns) {
      
      numMissingPts <- elimPoints[numMissingPts_index]
      result <- harmonic_nls_algorithm(ts, window_EVI_1, window_EVI_2, numMissingPts, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay)
      
      peak_results[runIndex, numMissingPts_index] <- result['midSeason']
      quarterPd_results[runIndex, numMissingPts_index] <- result['quarterPd_comparable']
    }
  }
  
  peak_means <- colMeans(peak_results, na.rm = TRUE)
  peak_sd <- apply(peak_results, 2, sd, na.rm = TRUE)
  
  quarterPd_means <- colMeans(quarterPd_results, na.rm = TRUE)
  quarterPd_sd <- apply(quarterPd_results, 2, sd, na.rm = TRUE)
  
  # combine stats into named matrix
  results <- matrix(c(peak_means, peak_sd, quarterPd_means, quarterPd_sd), ncol = length(elimPoints), byrow = TRUE)
  rownames(results) <- c('peak_mean', 'peak_sd', 'quarterPd_mean', 'quarterPd_sd')
  colnames(results) <- elimPoints
  
  return(results)
}

#print(run_harmonic_nls_algorithm(ts, 10, 0, 10, 20, 40, 140, 130, 240, '2016-10-01', '2017-07-01'))

# change the smoothing, and plot how results change as data degrades
# smoothing_names is the name to assign to each combo of smoothing windows
# NOTE, the smoothing options are pairwise, NOT window_EVI_1_vector x window_EVI_2_vector
test_smoothing_harmonic_nls <- function(ts, numRuns, elimPoints, window_EVI_1_vector, window_EVI_2_vector, smoothing_names, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {
  
  # add to this as get peak and quarter period results for each smoothing type
  # jitter_amount is for plotting points that aren't completely overlaid on each other
  plot_df <- data.frame(smoothing_name = character(0), eliminated_points = numeric(0), peak_mean = numeric(0), peak_sd = numeric(0),
                        quarterPd_mean = numeric(0), quarterPd_sd = numeric(0), jitter_amount = numeric(0))
  
  for (smoothingIndex in 1:length(smoothing_names)) {
    
    # get the smoothing parameters
    window_EVI_1 <- window_EVI_1_vector[smoothingIndex]
    window_EVI_2 <- window_EVI_2_vector[smoothingIndex]
    
    smoothing_name <- smoothing_names[smoothingIndex]
    
    # run algorithm the appropriate number of times
    results <- run_harmonic_nls_algorithm(ts, numRuns, elimPoints, window_EVI_1, window_EVI_2, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay)
    plot_df <- rbind(plot_df, data.frame(smoothing_name = rep(smoothing_name, length(elimPoints)), eliminated_points = elimPoints, peak_mean = results['peak_mean',], peak_sd = results['peak_sd',], quarterPd_mean = results['quarterPd_mean',], quarterPd_sd = results['quarterPd_sd',], jitter_amount = rep(smoothingIndex/10, length(elimPoints))))

    # transpose results before cleaning and plotting
    results <- as.data.frame(t(results))
    results_toKeep <- complete.cases(results)
    results <- results[results_toKeep,]
    
    # plot the results
    plot(elimPoints[results_toKeep], results$peak_mean, main = paste0('mean peak for ', smoothing_name), ylab = 'peak [day]', xlab = 'num points eliminated',
         ylim = c(min(results$peak_mean-results$peak_sd), max(results$peak_mean+results$peak_sd)))
    arrows(elimPoints[results_toKeep], results$peak_mean-results$peak_sd, elimPoints[results_toKeep], results$peak_mean+results$peak_sd, length=0.05, angle=90, code=3)

    plot(elimPoints[results_toKeep], results$quarterPd_mean, main = paste0('mean quarterPd for ', smoothing_name), ylab = 'quarterPd [day]', xlab = 'num points eliminated',
         ylim = c(min(results$quarterPd_mean-results$quarterPd_sd), max(results$quarterPd_mean+results$quarterPd_sd)))
    arrows(elimPoints[results_toKeep], results$quarterPd_mean-results$quarterPd_sd, elimPoints[results_toKeep], results$quarterPd_mean+results$quarterPd_sd, length=0.05, angle=90, code=3)
  }
  
  plot_df <- plot_df[complete.cases(plot_df),]
  
  plot_df$eliminated_points_toPlot <- plot_df$eliminated_points + plot_df$jitter_amount
  
  plot_df <- plot_df %>% group_by(smoothing_name)
  
  peak_summary_plot <- ggplot(plot_df) +
    geom_line(data = plot_df, aes(eliminated_points_toPlot, peak_mean, color = smoothing_name)) +
    geom_point(data = plot_df, aes(eliminated_points_toPlot, peak_mean, color = smoothing_name)) +
    geom_errorbar(data = plot_df,
                  aes(eliminated_points_toPlot, peak_mean, ymin = peak_mean - peak_sd, ymax = peak_mean + peak_sd, color = smoothing_name),
                  width = 0.4) +
    ggtitle('Peak, harmonic nls') +
    xlab('Number of eliminated points') +
    ylab('Peak DOY since Aug 1')
    
  quarterPd_summary_plot <- ggplot(plot_df) +
    geom_line(data = plot_df, aes(eliminated_points_toPlot, quarterPd_mean, color = smoothing_name)) +
    geom_point(data = plot_df, aes(eliminated_points_toPlot, quarterPd_mean, color = smoothing_name)) +
    geom_errorbar(data = plot_df,
                  aes(eliminated_points_toPlot, quarterPd_mean, ymin = quarterPd_mean - quarterPd_sd, ymax = quarterPd_mean + quarterPd_sd, color = smoothing_name),
                  width = 0.4) +
    ggtitle('Quarter period, harmonic nls') +
    xlab('Number of eliminated points') +
    ylab('Quarter period [days]')
    
  print(peak_summary_plot)
  print(quarterPd_summary_plot)
}


```

## Harmonic nls computation

```{r}
test_smoothing_harmonic_nls(ts, 5, seq(0, 10), c(0, 0, 20), c(0, 20, 20), c('no smoothing', 'half smoothing', 'full smoothing'), 50, 120, 110, 190, '2016-10-01', '2017-06-01')
```
