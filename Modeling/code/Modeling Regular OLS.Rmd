---
title: "Regular OLS"
output: html_document
---

1. Stepwise model selection, without spatial or temporal autocorrelation
2. Regular OLS for all years and for one year
3. Model evaluation (residual plots, residual autocorrelation)

## read data

```{r}

library(ggplot2)
library(tidyverse)
library(broom)
library(dplyr)
library(rgdal)
library(rgeos)
library(raster)
library(sf)
library(sp)
library(tmap)
library(viridis)
library(spdep)
library(spatialreg)
library(splm)
library(lmtest)
library(Metrics)

#E:/R-code/Modeling/code/FCN_clean_csvs.R
#~/Documents/R-code
source('E:/R-code/Modeling/code/FCN_clean_csvs.R')

MT_outline <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/MatoGrossoOutline', layer = 'MatoGrossoOutline')
crs(MT_outline) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

median_cell_raw <- read.csv('E:/R-code/Modeling/data/median_onset_cell_v2.csv')
percentile5_cell_raw <- read.csv('E:/R-code/Modeling/data/percentile5_onset_cell_v2.csv')
percentile95_cell_raw <- read.csv('E:/R-code/Modeling/data/percentile95_onset_cell_v2.csv')

median_muni_raw <- read.csv('E:/R-code/Modeling/data/median_muni_v2.csv')
percentile5_muni_raw <- read.csv('E:/R-code/Modeling/data/percentile5_muni_v2.csv')
percentile95_muni_raw <- read.csv('E:/R-code/Modeling/data/percentile95_muni_v2.csv')

median_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/median_CARpoly_v2.csv')
percentile5_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/percentile5_CARpoly_v2.csv')
percentile95_CARpoly_raw <- read.csv('E:/R-code/Modeling/data/percentile95_CARpoly_v2.csv')

grid_1deg <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/grid_1deg', layer = 'grid_1deg')
munis <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/munis', layer = 'munis_SHP')
crs(munis) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
  
MT_outline <- readOGR(dsn = 'E:/R-code/Modeling/data/shp/MatoGrossoOutline', layer = 'MatoGrossoOutline')
crs(MT_outline) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

cell_sf <- st_read(dsn = 'E:/R-code/Modeling/data/shp/median_onset_cell', layer = 'median_onset_cell_SHP')

min_soy_area <- 2 #km2. min area of total or SC/DC soy in cell, muni or property to be considered in model


```

## functions

```{r}
# test the models
test_plots <- function(model, model_name) {
  
  plot(model$residuals, main = paste("residual vs index", model_name))

  plot(model$fitted.values, model$residuals, main = paste("fitted values vs residuals", model_name))
  
  # normal probability plot
  qqnorm(model$residuals, pch = 1, frame = FALSE, main = model_name)
  qqline(model$residuals, col = "steelblue", lwd = 2)
}

# add cell_ID
clean_cell_ID <- function(cell_ID) {
  strsplit(cell_ID, "_")[[1]][2]
}

# plot data
plot_cell_onset <- function(year, cell_data) {
  cell_year <- cell_data[cell_data$year == year, ]
  
  ggplot(cell_year) +
   geom_sf(aes(fill = onset)) +
   scale_fill_viridis() +
   ggtitle(paste("Onset for basic OLS", year)) +
   geom_polygon(data = MT_outline, aes(x = long, y = lat), color = "black", alpha = 0, linetype = 1) +
   theme_bw()
}

plot_cell_residuals <- function(year, cell_data, intensity) {
  cell_year <- cell_data[cell_data$year == year, ]
  
  ggplot(cell_year) +
   geom_sf(aes(fill = residuals)) +
   scale_fill_viridis() +
   ggtitle(paste(intensity, "residuals for basic OLS", year)) +
   geom_polygon(data = MT_outline, aes(x = long, y = lat), color = "black", alpha = 0, linetype = 1) +
   theme_bw()
}

plot_cell_plant <- function(year, cell_data, intensity) {
  cell_year <- cell_data[cell_data$year == year, ]
  
  ggplot(cell_year) +
   geom_sf(aes(fill = plant)) +
   scale_fill_viridis() +
   ggtitle(paste(intensity, "plant for basic OLS", year)) +
   geom_polygon(data = MT_outline, aes(x = long, y = lat), color = "black", alpha = 0, linetype = 1) +
   theme_bw()
}

plot_cell_tempAuto <- function(year, cell_data, intensity) {
  cell_year <- cell_data[cell_data$year == year, ]
  
  ggplot(cell_year) +
   geom_sf(aes(fill = dwi.autocorr.p.value)) +
   scale_fill_viridis() +
   ggtitle(paste(intensity, "signif temporal autocorrelation for basic OLS", year)) +
   geom_polygon(data = MT_outline, aes(x = long, y = lat), color = "black", alpha = 0, linetype = 1) +
   theme_bw()
}

```

## read and clean spatial data

```{r}

# CSV DATA -----------------------------------------------------------------------------------------------------------------
# rename columns of CARpoly data and combine into a single csv before spatial join
median_CARpoly_raw <- rename_cols_median_CARpoly(median_CARpoly_raw)
percentile5_CARpoly_raw <- rename_cols_percentile5_CARpoly(percentile5_CARpoly_raw)
percentile95_CARpoly_raw <- rename_cols_percentile95_CARpoly(percentile95_CARpoly_raw)
CARpoly_raw <- create_CARpoly_raw(median_CARpoly_raw, percentile5_CARpoly_raw, percentile95_CARpoly_raw)
CARpoly_raw <- join_CARpoly_to_muni(CARpoly_raw)

# median cell
median_cell <- median_cell_raw %>% delete_cols_median_cell() %>%
                                    rename_cols_median_cell()
percentile5_cell <- percentile5_cell_raw %>% filter(year > 0)
percentile95_cell <- percentile95_cell_raw %>% filter(year > 0)

# median muni
median_muni <- median_muni_raw %>% rename_cols_median_muni()
percentile5_muni <- percentile5_muni_raw %>% filter(year > 0)
percentile95_muni <- percentile95_muni_raw %>% filter(year > 0)

# create tidy datasets
cell_tidy <- tidy_combine_cell(median_cell, percentile5_cell, percentile95_cell)
muni_tidy <- tidy_combine_muni(median_muni, percentile5_muni, percentile95_muni)
CARpoly_tidy <- tidy_CARpoly(CARpoly_raw)

# categorize numeric variables
cell_tidy <- categorize_vars_cell_tidy(cell_tidy)
cell_untidy <- categorize_vars_cell_untidy(median_cell)

muni_tidy <- categorize_vars_muni_tidy(muni_tidy)
muni_untidy <- categorize_vars_muni_untidy(median_muni)

CARpoly_tidy <- categorize_vars_CARpoly_tidy(CARpoly_tidy) %>% delete_cols_CARpoly_tidy()
CARpoly_untidy <- categorize_vars_CARpoly_untidy(CARpoly_raw)

# change rename cols and delete unnecessary cols
CARpoly_untidy <- CARpoly_untidy %>% rename_cols_CARpoly_untidy() %>%
                                    delete_cols_CARpoly_untidy()
  
# categorize as new or old or neither in planted soy age (so far only have it for cell scale)
cell_tidy <- cell_tidy %>% cell_categorize_soy_age()
cell_untidy <- cell_untidy %>% cell_categorize_soy_age()

# add year_index and year_factor
cell_tidy$year_index <- cell_tidy$year - 2003
cell_untidy$year_index <- cell_untidy$year - 2003
muni_tidy$year_index <- muni_tidy$year - 2003
muni_untidy$year_index <- muni_untidy$year - 2003
CARpoly_tidy$year_index <- CARpoly_tidy$year - 2003
CARpoly_untidy$year_index <- CARpoly_untidy$year - 2003

cell_tidy$year_factor <- cell_tidy$year %>% as.factor()
cell_untidy$year_factor <- cell_untidy$year %>% as.factor()
muni_tidy$year_factor <- muni_tidy$year %>% as.factor()
muni_untidy$year_factor <- muni_untidy$year %>% as.factor()
CARpoly_tidy$year_factor <- CARpoly_tidy$year %>% as.factor()
CARpoly_untidy$year_factor <- CARpoly_untidy$year %>% as.factor()

# use muni_code as factor
cell_tidy$Muni_code_factor <- cell_tidy$Muni_code %>% as.factor()
cell_untidy$Muni_code_factor <- cell_untidy$Muni_code %>% as.factor()
CARpoly_tidy$Muni_code_factor <- CARpoly_tidy$Muni_code %>% as.factor()
CARpoly_untidy$Muni_code_factor <- CARpoly_untidy$Muni_code %>% as.factor()

# SF DATA ------------------------------------------------------------------------------------------------

cell_sf$cell_ID <- median_cell$cell_ID
cell_sf$cell_ID <- sapply(as.character(cell_sf$cell_ID), clean_cell_ID)


cell_sf_tidy <- cell_sf %>% tidy_by_intensity_plant("SC_plant", "DC_plant") %>%
            #tidy_by_intensity_delay("SC_delay", "DC_delay") %>%
            dplyr::select(-c(SC_harvest, DC_harvest))
cell_sf_tidy$year_index <- cell_sf_tidy$year - 2003

```

## modeling functions

```{r}

# list of numeric x variable names, to be used in multicollinearity test
numeric.x.var.names <- c("onset", "latitude", "longitude", "onset_historicalRange", "year", "year_index")

# do linear model
# NEEDS year fixed effect, spatial fixed effect, FE vs ME, spatial autocorrelation handling
do_lm <- function(data, y.var,  spatial.auto.model, x.vars,
                  crop.intensity, mask.soy.area) {
  # options:
  # x.vars = vector of predictors, names of variables are in quotes, and interactions as will be written in the lm formula, e.g. onset:latitude
  # crop.intensity = "none", "DC", "SC"
  # spatial.fe.scale = "none", "regions.4", "municipality", "grid.1deg", "geo.weighted"
  # spatial.auto.model = "none", "spatial.lag", "spatial.error"
  # interaction.pairs = 
  # mask.soy.area = TRUE or FALSE, if TRUE take out rows with total soy area below min_soy_area
  
  # subset the data  --------------------------------------------------------------------------------------------------------
  # get only the desired cropping intensity
  data.subset <- if(crop.intensity == "none") {
    data
  } else {
    data[data$intensity == crop.intensity,]
  }
  
  # get rid of observations with low soy area
  data.subset <- if(mask.soy.area) {
    data.subset[data.subset$total_planted_area_km2 >= min_soy_area,]
  }
  
  # define the formula ------------------------------------------------------------------------------------------------------
  # define the basic formula
  formula.string <- paste(y.var, paste(x.vars, collapse = " + "), sep = " ~ ")
  
  f <- as.formula(formula.string)

  # do the model -------------------------------------------------------------------------------------------------------------
  # evaluate model. note, simpler alternative: model <- lm(f, data = data.subset)
  model <- eval(bquote(   lm(.(f), data = data.subset)   ))
  
  return(model)
}


# given an initial model, step through potential new predictors and pick the best one. 
add_predictor_stepwise <- function(data, initial.predictors, y.var, spatial.auto.model,
                                   new.predictors, crop.intensity, mask.soy.area) {
  
  # given an initial set of predictors, add another one based on adj R2
  # notes:
  # the data determines the observation scale
  # interactions to explore are in new.predictors
  # spatial FE scale is determined in the initial.predictors and interaction terms
  
  # calculate adj R2 of initial model
  initial_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = initial.predictors, 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
  
  initial_adjR2 <- summary(initial_model)$adj.r.squared
  
  # initialize 'best' new predictor and best adj_R2
  best_new_predictor <- "none"
  current_best_adjR2 <- initial_adjR2
  
  # initialize vector to store adj R2
  new_adjR2s <- c(initial_adjR2)
  
  # loop through potential new predictors
  for (predictor in new.predictors) {
    
    # calculate new adjR2 and save it
    new_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = c(initial.predictors, predictor), 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
    
    new_adjR2 <- summary(new_model)$adj.r.squared
    new_adjR2s <- c(new_adjR2s, new_adjR2)
    
    # if new_adjR2 is better, update the new_best_predictor
    if (new_adjR2 > current_best_adjR2) {
      current_best_adjR2 <- new_adjR2
      best_new_predictor <- predictor
    }
  }
  
  # return best predictor, its adjR2, and the list of other predictors' R2
  all_adjR2 <- data.frame(model = c("initial", new.predictors), adjR2 = new_adjR2s)
  
  return(list(new_predictor = best_new_predictor, 
              new_adjR2 = current_best_adjR2,  
              adjR2_table = all_adjR2))
}

# runs add_predictor_stepwise to build the final model
produce_model_stepwise <- function(data, initial.predictors, y.var, spatial.auto.model,
                                   new.predictors, crop.intensity, mask.soy.area, max.predictors) {
  # notes
  # max.predictors = the max allowed number of predictors in the model
  
  model_finalized <- FALSE
  iterations <- 0
  
  while (!model_finalized & iterations <= 10) {
    
    iterations <- iterations + 1
    
    # add a new predictor, save results
    result <- add_predictor_stepwise(data, initial.predictors, y.var, spatial.auto.model,
                       new.predictors, crop.intensity, mask.soy.area)
    
    new_predictor <- result$new_predictor
    new_adjR2_table <- result$adjR2_table
    new_adjR2 <- result$new_adjR2

    print(new_adjR2_table)
    
    # check if the model returned 'none' or the max.predictors was reached; if so, model is finalized
    # if model is finalized, return the model
    if (new_predictor == "none" | length(initial.predictors) >= max.predictors) { 
      model_finalized <- TRUE
      
      final_predictors <- initial.predictors
      final_adjR2 <- new_adjR2
      
      # run the final model to return the lm output
      final_model <- do_lm(data = data, 
              y.var = y.var, 
              x.vars = final_predictors, 
              spatial.auto.model = spatial.auto.model,  
              crop.intensity = crop.intensity,
              mask.soy.area = mask.soy.area)
      
    }
    
    # if model isn't done adding predictors, update initial.predictors for the new iteration
    initial.predictors <- c(initial.predictors, new_predictor)
    
  }
  
  # return
  return(list(final_model = final_model,
              final_predictors = final_predictors,
              final_adjR2 = final_adjR2))
}

evaluate_model <- function(lm_results, test.x.vars, orig_data, title) {
  
  print(title)
  print(summary(lm_results))
  plot(lm_results, which = c(1,2), main = title) # test error is homoscedastic, zero mean, normal
  
  # test pearson's correlation for numeric variables used
  df <- orig_data %>% subset(select = test.x.vars[test.x.vars %in% numeric.x.var.names])
  test.corr <- cor(df)
  
  print(c('predictor correlation matrix', title))
  print(test.corr)
}




```

## building a model stepwise automated

```{r}
# remove variables
rm(data)
rm(initial.predictors)
rm(y.var)
rm(spatial.auto.model)
rm(new.predictors)
rm(crop.intensity)
rm(mask.soy.area)

# test produce_model_stepwise
data <- muni_tidy
initial.predictors <- c("onset", "intensity")
y.var <- "plant_median"
spatial.auto.model <- "none"
new.predictors <- c("latitude", "longitude", "region", # for spatial effects
                     "year_factor", # for time effects
                    "onset_historicalRange",  # other predictors
                    "onset:latitude", "onset:longitude", "onset:region", # interactions: for spatial effects
                    "onset:year_factor", # interactions: for time effects
                    "onset:intensity") # interactions: other predictors
crop.intensity <- "none"
mask.soy.area <- TRUE


model <- produce_model_stepwise(data, initial.predictors, y.var, spatial.auto.model,
                       new.predictors, crop.intensity, mask.soy.area, 6)
evaluate_model(model$final_model, model$final_predictors, data, "output from produce_model_stepwise")


```

## spatial studies: first, check residual autocorrelation in basic OLS (for all years)

```{r}

year_oi <- 2008

# do basic OLS model --------------------------------------------------------------------------------------------------

cell_sf_tidy <- cell_sf_tidy %>%  drop_na %>%
                              mutate(year_factor = as.factor(year))

model_ols <- lm(plant ~ onset + intensity + lat + year + onset:intensity, data=cell_sf_tidy)
summary(model_ols)
cell_sf_tidy$residuals <- residuals(model_ols)
cell_sf_tidy$fitted.values <- fitted.values(model_ols)

# model evaluation: plant and onset maps (only those used in the actual modeling) --------------------------------------
print(plot_cell_onset(year_oi, cell_sf_tidy))
print(plot_cell_plant(year_oi, cell_sf_tidy[cell_sf_tidy$intensity == "DC",], "DC"))

# model evaluation: residual vs fitted value and vs index, and residual qq plot ----------------------------------------
test_plots(model_ols, "model_ols, all years")
plot(cell_sf_tidy$plant, cell_sf_tidy$fitted.values, main = "regular OLS fitted value vs actual value of plant")
abline(h = mean(cell_sf_tidy$fitted.values), col = "blue")
abline(v = mean(cell_sf_tidy$plant), col = "blue")
abline(0,1, col = "gray", lwd = 3)

# model evaluation: residual map --------------------------------------------------------------------------------------

plot(cell_sf_tidy$plant, cell_sf_tidy$residuals, main = "plant vs residuals")
print(plot_cell_residuals(year_oi, cell_sf_tidy[cell_sf_tidy$intensity == "DC",], "DC"))


# model evaluation: calculate R2 ---------------------------------------------------------------------------------------

SST <- sum((cell_sf_tidy$plant - mean(cell_sf_tidy$plant))^2)
SSE <- sum((cell_sf_tidy$residuals - mean(cell_sf_tidy$residuals))^2)
R2 <- 1 - SSE/SST

print(paste('R2:', R2))

# model evaluation: correlations between plant and explanatory variables---------------
print(paste("corr plant-onset", cor(cell_sf_tidy$plant, cell_sf_tidy$onset)))
print(paste("corr plant-lat", cor(cell_sf_tidy$plant, cell_sf_tidy$lat)))
print(paste("corr plant-year", cor(cell_sf_tidy$plant, cell_sf_tidy$year)))


plot(cell_sf_tidy$onset, cell_sf_tidy$residuals, main = "regular OLS, onset vs residual (exogeneity)")
plot(cell_sf_tidy$lat, cell_sf_tidy$residuals, main = "regular OLS, latitude vs residual (exogeneity)")
plot(cell_sf_tidy$year, cell_sf_tidy$residuals, main = "regular OLS, year vs residual (exogeneity)") 
abline(h = 0)

# multicollinearity: correlation between predictors
predictors <- cell_sf_tidy[,c("lat", "onset", "year")]
st_geometry(predictors) <- NULL
print(cor(predictors))

# model evaluation: see if basic OLS residuals are spatially autocorrelated with scatterplot -------------------------
# do with only ONE year!
to_autocorrelation <- cell_sf_tidy[cell_sf_tidy$year == year_oi & cell_sf_tidy$intensity == "DC", ]
nb <- poly2nb(to_autocorrelation)
#resnb <- sapply(nb, function(x) mean(to_autocorrelation$residuals[x]))
#plot(to_autocorrelation$residuals, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = "Basic OLS, all years")
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols_residuals <- moran.mc(to_autocorrelation$residuals, lw, 999, zero.policy = TRUE)
print('moran I of residuals with basic ols')
print(moran_basic_ols_residuals)
moran_basic_ols_onset <- moran.mc(to_autocorrelation$onset, lw, 999, zero.policy = TRUE)
print('moran I of onset with basic ols')
print(moran_basic_ols_onset)
moran_basic_ols_plant <- moran.mc(to_autocorrelation$plant, lw, 999, zero.policy = TRUE)
print('moran I of plant with basic ols')
print(moran_basic_ols_plant)

# # see if basic OLS residuals are temporally autocorrelated -----------------------------------------------------------
# 
# # create observation data frame, for DC only. 
# # need to rename cell_ID so the same cell_ID can correspond to multiple years
DC_cell <- cell_sf_tidy[cell_sf_tidy$intensity == "DC",] 
# 
# # filter out all cells where there isn't data for all years
st_geometry(DC_cell) <- NULL
DC_cell <- DC_cell[complete.cases(DC_cell),]
cells_list <- list()
i <- 1
for (year in 2004:2014) {
   cells_in_year <- DC_cell[DC_cell$year == year,]
   cells_list[[i]] <- cells_in_year$label
   i <- i + 1
}
full_data_cells <- Reduce(intersect, cells_list)
DC_cell <- DC_cell[DC_cell$label %in% full_data_cells, ]

# # create observation data frame, for SC only. 
# # need to rename cell_ID so the same cell_ID can correspond to multiple years
# SC_cell <- cell_sf_tidy[cell_sf_tidy$intensity == "SC",] 
# 
# # filter out all cells where there isn't data for all years
# st_geometry(SC_cell) <- NULL
# SC_cell <- SC_cell[complete.cases(SC_cell),]
# cells_list <- list()
# i <- 1
# for (year in 2004:2014) {
#   cells_in_year <- SC_cell[SC_cell$year == year,]
#   cells_list[[i]] <- cells_in_year$label
#   i <- i + 1
# }
# full_data_cells <- Reduce(intersect, cells_list)
# SC_cell <- SC_cell[SC_cell$label %in% full_data_cells, ]
# 
# 
DC_nested_cell <- group_by(data.frame(DC_cell), label) %>% nest()
# SC_nested_cell <- group_by(data.frame(SC_cell), label) %>% nest()
# 
dwtest_one_cell <- function(data) {
   dwtest(residuals ~ 1, data = data)
}

DC_cell <- DC_nested_cell %>%
  mutate(dwtest = map(data, dwtest_one_cell)) %>%
  mutate(test_df = map(dwtest, tidy)) %>%
  unnest(test_df)

# SC_cell <- SC_nested_cell %>%
#   mutate(dwtest = map(data, dwtest_one_cell)) %>%
#   mutate(test_df = map(dwtest, tidy)) %>%
#   unnest(test_df)
# 
# calculate proportion of p values below 5% significance, with Bonferroni correction
# 
DC_percent_auto <- mean(DC_cell$p.value < 0.05/nrow(DC_cell)) * 100
# SC_percent_auto <- mean(SC_cell$p.value < 0.05/nrow(SC_cell)) * 100
# 
print(DC_percent_auto)
# print(SC_percent_auto)
# 
# # plot areas with temporal autocorrelation in residuals
# # DC
DC_temporalAuto <- as.data.frame(DC_cell[, c("label", "p.value")]) %>%
                      mutate(dwi.autocorr.p.value = p.value)
cell_sf_tidy_DC_tmp <- merge(cell_sf_tidy, DC_temporalAuto)
cell_DC_tempAuto <- cell_sf_tidy_DC_tmp %>%
                      filter(dwi.autocorr.p.value < 0.05)

# # SC
# SC_temporalAuto <- as.data.frame(DC_cell[, c("label", "p.value")]) %>%
#                       mutate(dwi.autocorr.p.value = p.value)
# cell_sf_tidy_SC_tmp <- merge(cell_sf_tidy, SC_temporalAuto)
# cell_SC_tempAuto <- cell_sf_tidy_SC_tmp %>%
#                       filter(dwi.autocorr.p.value < 0.05)
# 
plot_cell_tempAuto(year_oi, cell_DC_tempAuto, "DC")
# plot_cell_tempAuto(year, cell_SC_tempAuto, "SC")

# print map to show cell_ID, for plotting residual, onset and plant over time

# pal <- colorNumeric(
#   palette = "YlGnBu",
#   domain = cell_DC_tempAuto$dwi.autocorr.p.value
# )
# 
# leaflet(cell_DC_tempAuto) %>%
#   addTiles() %>%
#   addPolygons(weight = 0.1,
#     color = ~pal(dwi.autocorr.p.value),
#               popup = cell_DC_tempAuto$cell_ID) %>%
#   addLegend("bottomright", 
#             pal = pal,
#             values = ~dwi.autocorr.p.value,
#             title = "dwi.autocorr.p.value",
#             opacity = 1
# )
#  
# cell_ID_oi <- "+4285+5008"
# 
# specific_cell <- cell_sf_tidy %>% 
#                     filter(cell_ID == cell_ID_oi) %>%
#                     filter(intensity == "DC")
# 
# plot(specific_cell$year, specific_cell$residuals, col = "red", type = "l", lwd = 2.5,
#      ylim = c(-30, 50), ylab = "day", xlab = "year",
#      main = paste("regular OLS DC for cell", cell_ID_oi))
# lines(specific_cell$year, specific_cell$plant - mean(specific_cell$plant), col = "green")
# lines(specific_cell$year, specific_cell$onset- mean(specific_cell$onset), col = "blue")
# legend(2004, 50, legend=c("residual", "plant demeaned", "onset demeaned"),
#        col=c("red", "green", "blue"), lty=c(1,1,1))
```

## evaluate predictions

```{r}

# runs the model with options to eliminate a year
run_model <- function(full_data, year_to_elim, elim_year) {
  
  # separate training and test data
  if (elim_year) {
    train_data <- full_data[full_data$year != year_to_elim,]
    test_data <- full_data[full_data$year == year_to_elim,]
  }
  else {
    train_data <- full_data
    test_data <- full_data
  }
  
  model = lm(plant ~ onset + year_index + lat + intensity, data=train_data)
  model_intercept = lm(plant ~ 1, data=train_data)
  
  # extract onset coef and R2 from model
  onset_coef <- model$coefficients['onset']
  train_data$residuals <- residuals(model)
  SST <- sum((train_data$plant - mean(train_data$plant))^2)
  SSE <- sum((train_data$residuals - mean(train_data$residuals))^2)
  R2 <- 1 - SSE/SST
  
  # prediction
  prediction <- predict(model, test_data)
  error <- rmse(prediction, test_data$plant)
  
  prediction_intercept <- predict(model_intercept, test_data)
  error_intercept <- rmse(prediction_intercept, test_data$plant)
  
  diff_error <- error_intercept - error
  
  # output
  output <- c(as.integer(year_to_elim), onset_coef, R2, error, diff_error)
  names(output) <- c("eliminated_year", "onset", "R2", "RMSE", "RMSE_improvement")
  return(output)
}

prediction_results <- data.frame()

for (year in 2004:2014) {
  
  result <- run_model(cell_sf_tidy, year, TRUE)
  prediction_results <- rbind(prediction_results, result)
}

names(prediction_results) <- names(result)

plot(prediction_results$eliminated_year, prediction_results$RMSE, 
     ylab = "RMSE", xlab = "eliminated year", ylim = c(5, 25), type = "l", main = "Prediction RMSE, OLS")

plot(prediction_results$eliminated_year, prediction_results$RMSE_improvement, 
     ylab = "RMSE", xlab = "eliminated year", ylim = c(0, 10), type = "l", main = "Prediction RMSE improvement over intercept, OLS")

plot(prediction_results$eliminated_year, prediction_results$onset, type = "l", col = "red", ylab = "coef or R2", xlab = "eliminated year", ylim = c(0.1, 0.7), main = "Prediction onset and R2, OLS")
lines(prediction_results$eliminated_year, prediction_results$R2, col = "blue")
legend(2004, 0.65, legend = c("onset coef", "R2"), col = c("red", "blue"), lty= c(1,1))

```

## spatial studies: check residual autocorrelation in basic OLS for one year

```{r}

# test basic OLS for one year only (to be compared to spatial lag and spatial error) ----------------------------
year_oi <- 2008

cell_sf_tidy <- cell_sf_tidy %>%  drop_na

# filter a specific year
cell_sf_tidy_year <- cell_sf_tidy %>% filter(year == year_oi)
model_ols <- lm(plant ~ onset + intensity + lat + onset:intensity, data=cell_sf_tidy_year)
summary(model_ols)

# model evaluation: plant and onset maps (only those used in the actual modeling) --------------------------------------
print(plot_cell_onset(year_oi, cell_sf_tidy_year))
print(plot_cell_plant(year_oi, cell_sf_tidy_year[cell_sf_tidy_year$intensity == "DC",], "DC"))

# model evaluation: residual vs fitted value and vs index, and residual qq plot ----------------------------------------
test_plots(model_ols, "model_ols, one year")

# model evaluation: residual map ---------------------------------------------------------------------------------------
cell_sf_tidy_year$residuals <- residuals(model_ols)

print(plot_cell_residuals(year_oi, cell_sf_tidy_year[cell_sf_tidy_year$intensity == "DC",], "DC"))

# model evaluation: see if basic OLS residuals are spatially autocorrelated --------------------------------------------

nb <- poly2nb(cell_sf_tidy_year)
#resnb <- sapply(nb, function(x) mean(cell_sf_tidy_year$residuals[x]))
#plot(cell_sf_tidy_year$residuals, resnb, xlab='Residuals', ylab='Mean adjacent residuals', main = paste("Basic OLS,", year_oi))
lw <- nb2listw(nb, zero.policy = TRUE)
moran_basic_ols <- moran.mc(cell_sf_tidy_year$residuals, lw, 999, zero.policy = TRUE)
print('moran with basic ols, one year')
print(moran_basic_ols)

#DEBUGGING
firstQuarter <- cell_sf_tidy_year[0:400,]
secondQuarter <- cell_sf_tidy_year[401:800,]
thirdQuarter <- cell_sf_tidy_year[801:1200,]
fourthQuarter <- cell_sf_tidy_year[1201:nrow(cell_sf_tidy_year),]

DC_half <- cell_sf_tidy_year[cell_sf_tidy_year$intensity == "DC",]
SC_half <- cell_sf_tidy_year[cell_sf_tidy_year$intensity == "SC",]
```



## export

```{r}
# for app.R
cell_sf_tidy <- cell_sf_tidy %>%  drop_na %>%
                              mutate(year_factor = as.factor(year))
saveRDS(as(cell_sf_tidy, 'Spatial'), "./cell_spdf.rds")

```