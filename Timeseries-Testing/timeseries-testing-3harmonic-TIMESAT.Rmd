---
title: "timeseries-testing"
output: html_document
---

## Read in timeseries and clean

```{r}

library(imputeTS)
library(dplyr)
library(signal) # Savitsky-Golay fitting
library(dplyr)
library(zoo)
library(ggplot2)

# need to read in, because regardless of whether use smooth or unsmoothed EVI for the other fitting methods, must start with nonsmoothed EVI here. doubly smoothed EVI (20, 20) is in the csv
ts <- read.csv('point1.csv')[,1:2]

colnames(ts) <- c('date', 'EVI_raw')
ts$date <- as.Date(ts$date, '%d-%h-%y')
ts$day <- as.numeric(ts$date - as.Date('2016-08-01')) # number of days

year <- 2017
year_start = year - 1
year_end = year

# plot raw EVI for looking at datq quality, DOY for rising and falling limbs
plot(ts[ts$day >= 0 & ts$day <= 365,]$day, ts[ts$day >= 0 & ts$day <= 365,]$EVI_raw, main = 'raw EVI', xlab = 'DOY after Aug 1', ylab = 'EVI')

```

## Helper functions

```{r}

# function to smooth by certain number of days (not by index). numDays creates +/- window; so actual smoothing window is - numDays to + numDays
smooth_by_days <- function(numDays, t, values) {
  
  smoothed <- numeric(length(values))
  
  for (index in 1:length(values)) {
    
    # get time window
    day_center <- t[index]
    day_start <- day_center - numDays
    day_end <- day_center + numDays
    
    # get indices corresponding to time window
    indices <- which(t >= day_start & t <= day_end)
    
    # get average of values over the indices and save
    mean_value <- mean(values[indices], na.rm = TRUE)
    
    smoothed[index] <- mean_value
    
  }
  
  return(smoothed)
}

# calculate first derivative of smoothed EVI (forward 1st order difference)
calc_1st_deriv <- function(values) {
  
  derivatives <- numeric(length(values))
  
  for (index in 1:(length(values)-1)) {

    derivative <- values[index + 1] - values[index]

    derivatives[index] <- derivative
  }
  
  derivatives[length(values)] <- derivatives[length(values) - 1] # to make sure the 1st derivative length still matches total time
  
  return(derivatives)
}

```

## Harmonic fitting exactly as in TIMESAT

```{r}
# harmonic fitting function (doesn't estimate omega)
# given: fitting degree (window size for smoothing EVI; timeseries as df, columns of date and raw EVI; number of points to take out randomly; the DOY from Aug 1 of the windows over which can find the rising and falling limbs of the first crop
# returns: quarter period and peak date
# the fittingStartDay and fittingEndDay are the windows over which to fit harmonic function; make sure they cover the peak(s) but not the dry season

#risingLimb_start_DOY <- 50
#risingLimb_end_DOY <- 120
#fallingLimb_start_DOY <- 120
#fallingLimb_end_DOY <- 190 
#window_EVI_1 <- 0
#window_EVI_2 <- 0
#numMissingPts <- 8
#fittingStartDay <- '2016-10-01'
#fittingEndDay <- '2017-07-01'

harmonic_TIMESAT_algorithm <- function(ts, window_EVI_1, window_EVI_2, numMissingPts, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {
  
  omega <- (6*3.14/length(ts$day))
  
  # cut EVI to only Aug 1, 2016 to July 31, 2017
  targeted_start_day <- as.numeric(as.Date(fittingStartDay) - as.Date('2016-08-01'))
  targeted_end_day <- as.numeric(as.Date(fittingEndDay) - as.Date('2016-08-01'))
  targeted_days <- which(ts$day >= targeted_start_day & ts$day <= targeted_end_day) # index of days to target
  
  ts <- ts[targeted_days,]
  
  # cut out randomly selected missing dates; first make sure the points are sampled from days that have data
  missing_days <- sample(unique(ts[complete.cases(ts),]$day), numMissingPts, replace = F) # days to take out
  ts$EVI_raw[ts$day %in% missing_days] <- NA # replace the randomly selected dates' EVI_raw with 'NA'

  EVI_raw <- ts$EVI_raw
  t <- ts$day
  
  # smooth EVI series by 20 days, then 20 days
  EVI_smoothed1 <- smooth_by_days(window_EVI_1, t, EVI_raw)
  EVI_smoothed2 <- smooth_by_days(window_EVI_2, t, EVI_smoothed1)
  
  # clean up EVI_smoothed2. for every date, replace with mean of the 2 EVI points and linearly interpolate at NaN times
  ts_R <- data.frame(t, EVI_smoothed2)
  ts_R <- ts_R %>% group_by(t) %>%
          summarise_at(vars(EVI_smoothed2), mean)

  # from here, the data won't be doubled on each date!
  EVI_smoothed2 <- na.approx(ts_R$EVI_smoothed2, na.rm = FALSE)
  # there may still be NA's at tails of EVI_smoothed2. replace these with the nearest non-NA or the average if have multiple NA's
  NA_location <- which(is.na(EVI_smoothed2))
  if (length(NA_location) == 1) { # if there is an NA in EVI_smoothed2, replace it with nearest value
    if (NA_location == 1) {EVI_smoothed2[1] <- EVI_smoothed2[2]}
    else if ( NA_location == length(EVI_smoothed2)) {EVI_smoothed2[length(EVI_smoothed2)] <- EVI_smoothed2[length(EVI_smoothed2) - 1]}
  }
  
  if (length(NA_location) > 1) {
    EVI_smoothed2[which(is.na(EVI_smoothed2))] <- mean(EVI_smoothed2, na.rm = TRUE)
    }

  ts_R$EVI_smoothed2 <- EVI_smoothed2
  
  # harmonic fitting
  t_fitting <- ts_R$t
  wt <- omega*t_fitting/(2*3.14)
  

    
  # Fit. if smoothing fails, use try to return NA's for midSeason and quarterPeriod_comparable and exit function
  model_nls2 <- try(model_nls2 <- nls(EVI_smoothed2~c1 + c2*t_fitting + c3*(t_fitting^2) + c4*sin(wt) + c5*cos(wt) +
               c6*sin(2*wt) + c7*cos(2*wt) + 
               c8*sin(3*wt) + c9*cos(3*wt), 
             start = list(c1 = 0.5, c2 = 0, c3 = 0, 
                          c4 = 0, c5 = 0, c6 = 0,
                          c7 = 0, c8 = 0, c9 = 0
                          ),
             control = nls.control(maxiter = 2000, minFactor = 1e-7))
  )
  if(is(model_nls2, "try-error")) {
    results <- c(NA, NA)
    names(results) <- c('midSeason', 'quarterPd_comparable')
  
  return(results)
  }


  
  # find phenological dates, first make sure the dates found are for first crop, first or second half
  firstHalf_dates <- which(ts_R$t >= risingLimb_start_DOY & ts_R$t <= risingLimb_end_DOY) # rising limb of first crop
  t_firstHalf <- ts_R$t[firstHalf_dates]
  fittedEVI_firstHalf <- fitted(model_nls2)[firstHalf_dates]
  
  secondHalf_dates <- which(ts_R$t >= fallingLimb_start_DOY & ts_R$t <= fallingLimb_end_DOY) # falling limb of first crop
  t_secondHalf <- ts_R$t[secondHalf_dates]
  fittedEVI_secondHalf <- fitted(model_nls2)[secondHalf_dates]
  
  firstCrop_dates <- which(ts_R$t >= risingLimb_start_DOY & ts_R$t <= fallingLimb_end_DOY) # first crop
  t_firstCrop <- ts_R$t[firstCrop_dates]
  fittedEVI_firstCrop <- fitted(model_nls2)[firstCrop_dates]
  
  # date and value of max EVI
  maxEVI <- max(fittedEVI_firstCrop, na.rm = TRUE)
  minEVI_left <- min(fittedEVI_firstHalf, na.rm = TRUE)
  minEVI_right <- min(fittedEVI_secondHalf, na.rm = TRUE)
  
  date_min = approx(x = fittedEVI_firstCrop, y = t_firstCrop, xout = minEVI_left)$y
  date_max <- approx(x = fittedEVI_firstCrop, y = t_firstCrop, xout = maxEVI)$y
  
  # print('date_min')
  # print(date_min)
  
  # find phenological dates
  #rightOfPeakEVI <- 0.9*(maxEVI - minEVI_left) + minEVI_left
  #leftOfPeakEVI <- 0.9*(maxEVI - minEVI_right) + minEVI_right

  # date_rightOfPeak <- approx(x = fittedEVI_secondHalf, y = t_secondHalf, xout = rightOfPeakEVI)$y
  # date_leftOfPeak <- approx(x = fittedEVI_firstHalf, y = t_firstHalf, xout = leftOfPeakEVI)$y
  # 
  # if (is.na(date_rightOfPeak)) {date_rightOfPeak <- mean(risingLimb_start_DOY, fallingLimb_end_DOY)}
  # if (is.na(date_leftOfPeak)) {date_leftOfPeak <- mean(risingLimb_start_DOY, fallingLimb_end_DOY)}
  # 
  # midSeason <- mean(c(date_rightOfPeak, date_leftOfPeak))
  quarter_period_comparable <- (date_max - date_min)/2
  
  results <- c(date_max, quarter_period_comparable)
  names(results) <- c('midSeason', 'quarterPd_comparable')
  
  # plot(t_fitting, EVI_smoothed2, main = "3rd order harmonic, nls", xlab = "Days after August 1", ylab = "EVI", xlim = c(0, 350))
  # lines(t_fitting, EVI_smoothed2, col = "black")
  # lines(t_fitting, fitted(model_nls2), col = "red")
  # abline(v = date_min, col = "blue")
  # abline(v = date_max - quarter_period_comparable, col = "darkgreen")
  # abline(v = date_max, col = "blue")
  
  return(results)
}

# takes elimPoints, the vector of number of points to eliminate, and numRuns, the number of runs to do per number of points eliminated
run_harmonic_TIMESAT_algorithm <- function(ts, numRuns, elimPoints, window_EVI_1, window_EVI_2, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {

  # to hold results
  peak_results <- matrix(nrow = numRuns, ncol = length(elimPoints))
  quarterPd_results <- matrix(nrow = numRuns, ncol = length(elimPoints))
  
  # run with appropriate number of missing points
  for (numMissingPts_index in 1:length(elimPoints)) {
    for (runIndex in 1:numRuns) {
      
      numMissingPts <- elimPoints[numMissingPts_index]
      result <- harmonic_TIMESAT_algorithm(ts, window_EVI_1, window_EVI_2, numMissingPts, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay)
      
      peak_results[runIndex, numMissingPts_index] <- result['midSeason']
      quarterPd_results[runIndex, numMissingPts_index] <- result['quarterPd_comparable']
    }
  }
  
  peak_means <- colMeans(peak_results, na.rm = TRUE)
  peak_sd <- apply(peak_results, 2, sd, na.rm = TRUE)
  
  quarterPd_means <- colMeans(quarterPd_results, na.rm = TRUE)
  quarterPd_sd <- apply(quarterPd_results, 2, sd, na.rm = TRUE)
  
  # combine stats into named matrix
  results <- matrix(c(peak_means, peak_sd, quarterPd_means, quarterPd_sd), ncol = length(elimPoints), byrow = TRUE)
  rownames(results) <- c('peak_mean', 'peak_sd', 'quarterPd_mean', 'quarterPd_sd')
  colnames(results) <- elimPoints
  
  return(results)
}


# change the smoothing, and plot how results change as data degrades
# smoothing_names is the name to assign to each combo of smoothing windows
# NOTE, the smoothing options are pairwise, NOT window_EVI_1_vector x window_EVI_2_vector
test_smoothing_harmonic_TIMESAT <- function(ts, numRuns, elimPoints, window_EVI_1_vector, window_EVI_2_vector, smoothing_names, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay) {
  
  # add to this as get peak and quarter period results for each smoothing type
  # jitter_amount is for plotting points that aren't completely overlaid on each other
  plot_df <- data.frame(smoothing_name = character(0), eliminated_points = numeric(0), peak_mean = numeric(0), peak_sd = numeric(0),
                        quarterPd_mean = numeric(0), quarterPd_sd = numeric(0), jitter_amount = numeric(0))
  
  for (smoothingIndex in 1:length(smoothing_names)) {
    
    # get the smoothing parameters
    window_EVI_1 <- window_EVI_1_vector[smoothingIndex]
    window_EVI_2 <- window_EVI_2_vector[smoothingIndex]
    
    smoothing_name <- smoothing_names[smoothingIndex]
    
    # run algorithm the appropriate number of times
    results <- run_harmonic_TIMESAT_algorithm(ts, numRuns, elimPoints, window_EVI_1, window_EVI_2, risingLimb_start_DOY, risingLimb_end_DOY, fallingLimb_start_DOY, fallingLimb_end_DOY, fittingStartDay, fittingEndDay)
    plot_df <- rbind(plot_df, data.frame(smoothing_name = rep(smoothing_name, length(elimPoints)), eliminated_points = elimPoints, peak_mean = results['peak_mean',], peak_sd = results['peak_sd',], quarterPd_mean = results['quarterPd_mean',], quarterPd_sd = results['quarterPd_sd',], jitter_amount = rep(smoothingIndex/10, length(elimPoints))))

    # transpose results before cleaning and plotting
    results <- as.data.frame(t(results))
    results_toKeep <- complete.cases(results)
    results <- results[results_toKeep,]
    
 # plot the results
 plot(elimPoints[results_toKeep], results$peak_mean, main = paste0('mean peak for ', smoothing_name), ylab = 'peak [day]', xlab = 'num points eliminated',
      ylim = c(min(results$peak_mean-results$peak_sd), max(results$peak_mean+results$peak_sd)))
 arrows(elimPoints[results_toKeep], results$peak_mean-results$peak_sd, elimPoints[results_toKeep], results$peak_mean+results$peak_sd, length=0.05, angle=90, code=3)

 plot(elimPoints[results_toKeep], results$quarterPd_mean, main = paste0('mean quarterPd for ', smoothing_name), ylab = 'quarterPd [day]', xlab = 'num points eliminated',
      ylim = c(min(results$quarterPd_mean-results$quarterPd_sd), max(results$quarterPd_mean+results$quarterPd_sd)))
 arrows(elimPoints[results_toKeep], results$quarterPd_mean-results$quarterPd_sd, elimPoints[results_toKeep], results$quarterPd_mean+results$quarterPd_sd, length=0.05, angle=90, code=3)
   }
  
  plot_df <- plot_df[complete.cases(plot_df),]
  
  plot_df$eliminated_points_toPlot <- plot_df$eliminated_points + plot_df$jitter_amount
  
  plot_df <- plot_df %>% group_by(smoothing_name)
  
  # PEAK PLOT --------------------------------------------------------------------------------------------------------------------------
  peak_summary_plot <- ggplot(plot_df) +
    geom_line(data = plot_df, aes(eliminated_points_toPlot, peak_mean, color = smoothing_name), size = 2) +
    geom_point(data = plot_df, aes(eliminated_points_toPlot, peak_mean, color = smoothing_name)) +
    #geom_errorbar(data = plot_df, aes(eliminated_points_toPlot, peak_mean, ymin = peak_mean - peak_sd, ymax = peak_mean + peak_sd, color = smoothing_name), width = 0.4) +
    geom_ribbon(aes(x = eliminated_points_toPlot, ymin=peak_mean - peak_sd, 
                    ymax=peak_mean + peak_sd, color = smoothing_name), alpha=0.2) +
    scale_x_continuous(breaks=c(0,2,4,6,8,10)) +
    ylim(110, 145) +
    scale_color_manual(values = c('black', 'orange')) +
    theme_bw() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), 
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), 
text = element_text(size=15)) +
    ggtitle('Peak, harmonic TIMESAT') +
    xlab('Number of eliminated points') +
    ylab('Peak DOY since Aug 1')
    
  # QUARTER PERIOD PLOT ----------------------------------------------------------------------------------------------------------------
  quarterPd_summary_plot <- ggplot(plot_df) +
    geom_line(data = plot_df, aes(eliminated_points_toPlot, quarterPd_mean, color = smoothing_name), size = 2) +
    geom_point(data = plot_df, aes(eliminated_points_toPlot, quarterPd_mean, color = smoothing_name)) +
    #geom_errorbar(data = plot_df, aes(eliminated_points_toPlot, quarterPd_mean, ymin = quarterPd_mean - quarterPd_sd, ymax = quarterPd_mean + quarterPd_sd, color = smoothing_name), width = 0.4) +
    geom_ribbon(aes(x = eliminated_points_toPlot, ymin=quarterPd_mean - quarterPd_sd, 
                    ymax=quarterPd_mean + quarterPd_sd, color = smoothing_name), alpha=0.2) +
    scale_x_continuous(breaks=c(0,2,4,6,8,10)) +
    ylim(25, 55) +
    scale_color_manual(values = c('black', 'orange')) +
    theme_bw() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"),
axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), 
text = element_text(size=15)) +
    ggtitle('Quarter period, harmonic TIMESAT') +
    xlab('Number of eliminated points') +
    ylab('Quarter period [days]')
    
    print(peak_summary_plot)
    print(quarterPd_summary_plot)
}
```

## testing

```{r}
print(harmonic_TIMESAT_algorithm(ts, 0, 0, 0, 10, 120, 110, 200, '2016-09-01', '2017-07-01'))
```

## Computations for harmonic TIMESAT
```{r}

set.seed(2)

#test_smoothing_harmonic_TIMESAT(ts, 50, seq(0, 10), c(0, 0, 20), c(0, 20, 20), c('double smoothed EVI', 'single smoothed EVI', 'unsmoothed EVI'), 20, 140, 120, 190, '2016-09-01', '2017-07-01')

# fewer smoothing combinations
test_smoothing_harmonic_TIMESAT(ts, 50, seq(0, 10), c(20,  0), c(20, 0), c('smoothed EVI', 'unsmoothed EVI'), 20, 140, 120, 190, '2016-09-01', '2017-07-01')
```
